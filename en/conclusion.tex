\chapter{Conclusion}\label{sec:conclusion}

The aim of this thesis was to design and implement a~heightmap compression algorithm which could be, among other things, plugged into an existing real-time planet renderer. This algorithm should be able to compress a~regular square block of height samples and progressively decompress it in the~real-time, from the~smallest mip-map to the~largest one. Apart from this, the algorithm should not in any way interfere with the~rendering pipeline of the~application. After summarizing the~available literature, we decided to write our own method inspired by the~most promising compression approach used inside C-BDAM~\cite{cbdam}, the~method for rendering compressed flat terrain. Our method turned out to be suitable for the~purpose. The~decompression of one 256x256 square which is the~size of square used in the~application takes only about 1ms. The~compression of it takes about 30~ms which is still bearable, as it does not have to be performed in the~real time. The~compression ratios of our method are comparable to the~ones of ChspaceheadBDAM which provides the~best compression ratios among the~studied methods.

We also investigated the~possibility to perform the~decompression on GPU in order to spare RAM. However, the~main priority was still to minimize the~size of the~compressed data which is why we followed the~compression ratio in the~first place. With respect to it, we designed our method and only after this we analyzed whether and how its decompression could be put onto GPU. We saw two places where the~decompression could already switch to GPU:
\begin{enumerate}
	\item{before the~decompression of residuals}
	\item{right after the decompression of residuals}
\end{enumerate}

The~first possibility would imply that the~real-time decompression, as performed by Zlib, has to be put onto GPU. Alternatively, a~different lossless compression method could be picked, but Zlib achieves the~best compression ratios from among the~libraries we tested. As we already described in Sec.~\ref{sec:lossless_comp}, Zlib contains both LZ77 and Huffman coding. There are works dedicated to GPU implementation of LZ77~\cite{gpuLZ77Cuda1} and Huffman~\cite{gpuHuffman1, gpuHuffmanCuda1}, but they all require CUDA which is not used in many real-time renderers, not even in the~one inside which we have tested our method.

The~second possibility means less spared RAM, but still some, because, as we described in Sec.~\ref{sec:top-down}, before the~residuals are losslessly compressed, they are packed --- divided by their quantization interval, shifted, so they are all positive and then skewed to the~number of bits of the~largest value. So, right after their decompression by Zlib, they are still a~bit compressed. Theoretically, their unpacking could be done on GPU. Then, the~subsequent reconstruction of a~larger mip-map from the~smaller one would have to be performed on GPU, too. The~ability to do this surely depends on the~implementation of the~renderer. This is where we encountered a~problem.

The~renderer uses just one vertex buffer per each square. Then it sends a~mip-map of the~square to GPU as a~texture and according to the~heights in this texture, it performs displacement of vertices of the~buffer. Thus, if the~unpacking of residuals and the~progressive mip-maps reconstruction were all to be performed on GPU, we would no longer send any textures to GPU, but we would just send the~unpacked residuals there which is the~only remaining way how to spare RAM in our case. The~point is that all the~recostruction steps would then have to be performed on GPU, including creating an array and traversing it. The~only way how this can be done on GPU is with the~help of CUDA, OpenCL or compute shaders. However, the~implementation of the~renderer uses neither CUDA, nor OpenCL and during the~time of designing and writing the~method, it was written in DirectX9 which does not support compute shaders.  

The~second alternative we considered was to directly utilize the~information in vertices --- their location. To determine the~height of a~certain vertex, we would have to average the~suitably backward transformed heights of its neighbors (Sec.~\ref{sec:top-down}). This would have to be done in vertex shader. However, this is impossible, as in vertex shader, we cannot access neighboring vertices of the~current vertex.

To conclude, the~possibility to switch any part of the~real-time decompression onto GPU highly depends on the~implementation of the~renderer which uses the~method. The~limitations of our testing renderer made it impossible to switch any part of it onto GPU. However, just recently has the~renderer switched to DirectX11 already supporting compute shaders which opens the~door for all the~alternatives impossible before. Thus, the~decompression on GPU has quite a~huge potential and is interesting for future work. 