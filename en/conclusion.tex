\addcontentsline{toc}{chapter}{Conclusion}
\chapter*{Conclusion}\label{chap:conclusion}

The aim of this thesis was to design and implement a~heightmap compression algorithm which could be, among other things, plugged into an existing real-time planet renderer. This algorithm should be able to compress a~regular square block of height samples and progressively decompress it in the~real-time, from the~smallest mip-map to the~largest one. Apart from this, the algorithm should not in any way interfere with the~rendering pipeline of the~application. After summarizing the~available literature, we decided to write our own method inspired by the~most promising compression approach used inside C-BDAM~\cite{cbdam}, the~method for rendering compressed flat terrain. In our method, the~decompression of one 256x256 square which is the~size of square used in the~application takes only about 1ms. The~compression of it takes about 30~ms which is still bearable, as it does not have to be performed in the~real time. The~compression ratios of our method are comparable to the~ones of C-BDAM which provides the~best compression ratios among the~studied methods.

We also investigated the~possibility to perform the~decompression on the~GPU in order to spare RAM. However, the~main priority was still to minimize the~size of the~compressed data which is why we followed the~compression ratio in the~first place. With respect to it, we designed our method and only after this we analyzed whether and how its decompression could be put onto the~GPU. We saw two places where the~decompression could already switch to the~GPU:
\begin{enumerate}
	\item{before the~decompression of residuals}
	\item{right after the decompression of residuals}
\end{enumerate}

Both possibilities imply that the~reconstruction of data (the~predictions followed by the~adding of residuals) would be performed on the~GPU, whereas the~first one implies that in addition, the~lossless decoding of residuals would be performed there, too. Keep in mind that once the~decompression has switched to the~GPU, it cannot return from there. Otherwise, no RAM would be spared. The~point of this switch is that we send the~compressed data to the~GPU and decompress it just there, so that some RAM is spared. If we subsequently fetched the~decompressed data back from the~GPU in any point, we would not save any RAM.

The~first possibility would imply that the~real-time decompression, as performed by Zlib, has to be put onto the~GPU. Alternatively, a~different lossless compression method could be picked, but Zlib achieves the~best compression ratios from among the~libraries we tested. As we already described in Sec.~\ref{sec:lossless_comp}, Zlib contains both LZ77 and Huffman coding. There are works dedicated to the~GPU implementation of LZ77~\cite{gpuLZ77Cuda1} and Huffman~\cite{gpuHuffman1, gpuHuffmanCuda1}, but they all require CUDA which is not used in many real-time renderers, not even in the~one inside which we have tested our method. Moreover, these implementations do not take into account sharing of resources, so there is a~possibility of a~significant negative rendering performance hit.

The~second possibility means less spared RAM, but still some, because, as we described in Sec.~\ref{sec:top-down}, before the~residuals are losslessly compressed, they are packed --- divided by their quantization interval, shifted, so they are all positive and then skewed to the~number of bits of the~largest value. So, right after their decompression by Zlib, they are still a~bit compressed. Theoretically, their unpacking could be done on the~GPU. Then, the~subsequent reconstruction of a~larger mip-map from the~smaller one would have to be performed on the~GPU, too. The~ability to do this surely depends on the~implementation of the~renderer. This is where we encountered a~problem.

The~renderer uses just one vertex buffer per each square. Then it sends a~mip-map of the~square to the~GPU as a~texture and according to the~heights in this texture, it performs displacement of vertices of the~buffer. Thus, if the~unpacking of residuals and the~progressive mip-maps reconstruction were all to be performed on the~GPU, we would no longer send any textures to the~GPU, but we would just send the~unpacked residuals there which is the~only remaining way how to spare RAM in our case. The~point is that all the~recostruction steps would then have to be performed on the~GPU, including creating an array and traversing it. The~only way how this can be done on the~GPU is with the~help of CUDA, OpenCL or compute shaders. However, the~implementation of the~renderer uses neither CUDA, nor OpenCL and during the~time of designing and writing the~method, it was written in DirectX9 which does not support compute shaders.  

The~second alternative we considered was to directly utilize the~information in vertices --- their location. To determine the~height of a~certain vertex, we would have to average the~suitably backward transformed heights of its neighbors (Sec.~\ref{sec:top-down}). This would have to be done in vertex shader. However, this is impossible, as in vertex shader, we cannot access neighboring vertices of the~current vertex. The~alternative to it could be to use a~geometry or tessellation shader. However, this would be very complicated and would require serious modifications to the~renderer's pipeline.

To conclude, the~possibility to switch any part of the~real-time decompression onto the~GPU highly depends on the~implementation of the~renderer which uses the~method. The~limitations of our testing renderer made it very difficult to switch any part of it onto the~GPU. However, just recently has the~renderer switched to DirectX11 already supporting compute shaders which opens the~door for all the~alternatives impossible before. On the~other hand, the~GPU memory is currently the~main bottleneck, so sacrifying it to spare RAM could actually decrease the~overal performance.

Finally, after a~consultation with people from the~practice --- the~developers of the~testing renderer --- we decided to give up the~practical implementation on the~GPU. However, it still remains an~interesting possibility of future work for interested researchers.

In Attachment~\ref{att:cd}, we provide a~CD containing this method. In Attachment~\ref{att:res_ref}, we provide demonstrations how the~maximum deviation affects the~look of the~result. Last but not least, in Attachment~\ref{att:paper}, there is a~paper about this method written by us for a~computer graphics students conference.