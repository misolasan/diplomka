\addcontentsline{toc}{chapter}{Introduction}
\chapter*{Introduction}\label{chap:introduction}

A~planetary renderer based on real data has to work with huge amounts of information. This includes its storage and distribution to both the~developers working on the~application and the~users of it. Data compression can be very beneficial in this situation --- it can greatly reduce all the~storage demands. This results in decreased network and disk utilization --- the~data needed to transmit via network become smaller, so the~transmittion is quicker. Similarly for the~rendering, the~data which have to be fetched from disk into RAM are smaller which decreases the~transfer time, often being one of the~major real-time performance bottlenecks. 

In this kind of renderer, terrain information forms a~significant subset of the~utilized data. These are basically the~heights of the~terrain at all places of the~planet. To keep the~size of the~data reasonable, the~terrain height is usually discretely sampled in a~regular square grid of some density (eg. 90m per sample). Each one of these height samples is a~number --- either double (8~bytes) or float (4~bytes) or short (2~bytes) --- the~accuracy of which is sufficient enough for the~given purpose. This number stands for the~height at the~location of the~sample in meters. This thesis focuses on compression of this kind of data represented by float samples. 

Classical image compression techniques (eg. png, jpeg)~\cite{jpeg, basicFormats} are not suitable for this purpose, because they are designed to compress four 1-byte channels per pixel. They benefit from patterns and similarities of the~channel values among adjacent pixels. Putting a~4-byte float height value into four channels directly does not result in anything meaningful from which these methods might benefit ---  even with a~slight change of the~height value, all the~four channels, into which it has been put, can change significantly. This is why they do~not achieve good compression ratios when used this way. Of course, this might be sorted out by a~more sophisticated translation of the~height value into the~channels, but this approach would still not be able to control the~maximum absolute height error of the~compressed data which is a~very important feature for simulations. 

For example, if the~compression flattenned a~narrow but high peak, inside the~simulation it would be possible to choose a~flight trajectory through this peak which would result in a~collision in the~real world. Simply put, it is important to ensure that the~compressed data differ minimally from the~real data. Even though JPEG~2000 offers a~maximum deviation control, it is only able to control the~per-channel maximum error which is impossible to translate into the~height error, as a~single height value would be decomposed into four channels. Thus, heightmap compression requires a~different approach --- the~heights have to be handled directly as float values and similarity or closeness of adjacent height values has to be exploited.

Generally, every application designed to render huge scenes must implement some kind of multiresolution approach in order to keep the~rendering frame rates reasonable. This is called level of detail (LOD), i.e., degradation of quality of the~displayed data with the~growing distance in order to optimize the~rendering. A~planetary renderer certainly belongs to this group of applications, so among the~other things, it must somehow ensure that the further the~terrain is from the~camera, the~less detailed it is. With the~growing distance, the~amount of observable detail decreases anyway, so displaying it would be just an~unnecessary performance burden. 

Such LOD-ing approach is almost always implemented by a~multiresolution tree hierarchy of nodes~\cite{survey}. Usually, all these nodes have the~same form --- triangles, squares, multipolygons, etc. The~leaf (bottom-level) nodes of this hierarchy are the~partitions of the~original terrain data and the~other non-leaf nodes are gradual simplifications of the~leaf nodes --- the~higher the~level a~node belongs to (the~further it is from the~leaf level), the~coarser representation of data it presents. This hierarchy gives a~very good basis for the~subsequent multiresolution rendering of scene --- given a~camera position, we determine which nodes will be rendered on the~basis of their distance from the~camera, using an~appropriate metrics. This choice forms a~cut in the~hierarchy, with its lowest point at the~finest node --- the~one closest to the~camera. The~height of this cut increases with growing distance from the~camera. 

To prepare a~terrain LOD hierarchy, several transformations of the~input terrain data are required --- projecting it from the~geographic coordinates into the~space of the~LOD hierarchy followed by splitting it into its~basic partitions forming the~leaf nodes of the~hierarchy, which are then iteratively grouped into coarser parent nodes in order to build the~whole multiresolution hierarchy. The~nodes of this hierarchy from subsequent levels might either be stored completely independently from each other or dependently --- for the~children of a~certain node we remember just the~data which are required to reconstruct the~children from their parent. The~independent approach introduces significant data redundancy --- every non-leaf level of the~hierarchy stores independently again the~same terrain data as the~following finer level, just in a~coarser form. This results in the~greater size of the~resulting data hierarchy prepared for rendering. On the~other hand, this approach makes the~rendering quicker --- in order to fetch a~certain node, we do~not have to fetch the~data of all its ancestors. In practice, both approaches are used. The~application which served as a~testbed for our compression method uses the first approach --- every node of its LOD hierarchy is a~square, stored completely independenly from the~others. The~method designed by us should be able to compress such a~square, not interfering with the~LOD hierarchy of the~application at all --- not trying to remove the~redundancy caused by independent storage of its nodes in any way, because, at it has been said, it is beneficial in some aspects.

More precisely, the~aim of this thesis is to review the~existing heightmap compression methods and either find or come up with a~method which is able to compress a~regular square of float terrain samples the~dimension of which is $2^n$ as efficiently as possible, while enabling subsequent real-time progressive decompression of its data from the~coarsest to the~finest mip-map. Mip-mapping is a~standard method for multiresolution representations of textures. Mip-maps are gradually smaller and coarser squares with the~dimensions $2^{n-1 .. 0}$ representing the~same data~\cite{basics}. Usually, every pixel inside a~certain mip-map is the~average of the~four corresponding child pixels inside the~previous larger mip-map. This averaging can be performed in the~domain of colors, but in our case, it should be performed in the~domain of heights. The~decompression should be as fast as possible. We should explore the~possibility to perform the~decompression on GPU mainly in order to save RAM. We should keep in mind that from among the~mentioned optimization objectives, the~resulting size of compressed data is the~most important one. The~maximum absolute per-sample deviation of the~compressed data must be controllable by the~user. No rendering of data has to be handled, as it is supposed that the~renderer using this method will handle this. 

The~mip-maps which the~decompression should be able to provide are in fact a~form of level of detail technique too, but it must be made clear that the~ability to provide simplified multiresolution representations of every square of the~LOD hierarchy is just a~tiny part of the~multiresolution rendering pipeline, a~LODing terrain engine can certainly not be build solely on this ability. The~application using the~desired method should be able to traverse its multiresolution hierarchy of square nodes on itself in order to render a~scene. After selecting which squares should be displayed (the~lower the~distance, the~more detailed the~displayed square), the~application then should decide for each of the~squares which mip-map of it will be displayed. Thus, the~mip-maps present a~less significant LOD concept inside the~greater LOD concept --- the~multiresolution squares hierarchy. The~mip-map selection can be based on the~screen-space area of the~square in order to reduce the~terrain aliasing. For example, when looking at a~certain terrain square from a~side, a~coarser mip-map of it should be chosen than in case we look at it from the~top.

In Chapter~\ref{chap:related_works}, we list the~methods which contain heightmap compression and form a~conclusion to get inspired by the~compression used inside one of them named C-BDAM in order to build our own method. In Chapter~\ref{chap:preliminaries}, we briefly describe the~core component of compression in many of the~mentioned papers, including C-BDAM --- the~wavelet transform. Following this, we compare the~basic wavelet approaches to the~compression inside C-BDAM and our method. Lastly, we briefly describe the~basic methods of lossless compression which are often utilized in wavelet compression. In Chapter~\ref{chap:outline}, we briefly describe the~basic outline of our method. In Chapter~\ref{chap:details}, we describe the~details of the~method. In Chapter~\ref{chap:cbdam_comp}, we compare the~core algorithm of this method to the~algorithm of C-BDAM. We present the~results in Chapter~\ref{chap:results}. In Chapter~\ref{sec:conclusion}, we discuss these results along with the~possibility how the~decompression could be put onto GPU in order to spare RAM. So far, we have not found a~way how this could be done.