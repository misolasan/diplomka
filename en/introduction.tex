\chapter{Introduction}\label{chap:introduction}

In the~beginning of this chapter, we clearly state the~aim of this thesis and then briefly describe and summarize the~works most related to the~topic. In the~end, we present and explain our decision how to solve the~assignment which we made on the~basis of this literature.

The~aim of this thesis is to either find or come up with a~method which solves the~task as well as possible. The~task is just to compress a~regular square of float terrain samples as efficiently as possible, while enabling subsequent real-time progressive decompression of its data from the~coarsest to the~finest mip-map. The~decompression should be as fast as possible. The~maximum per-sample deviation of the~compressed data must be controllable by the~user. No rendering of data has to be handled, as it is supposed that the~application using this method will handle this. Knowing these requirements, we started researching the~available literature. However, we did not find any method which solves exactly this task while doing nothing additional which just decreases the~required efficiency for our purpose. The~point is, that most works related to heightmap compression are also able to render the~compressed data. Many times, the~compression is built into their multiresolution (LOD-ing\footnote{LOD is the~abbreviation of level of detail - degradation of quality of the~displayed data with the~growing distance in order to optimize the~rendering}) rendering pipeline. Of course, for a~terrain renderer, it is crucial to implement some form of multiresolution rendering in order to reach reasonable frame rates, but this is not what our method should handle. 

Our method should just be plugged into an~already existing multiresolution rendering engine, the~node of the~LOD hierarchy of which is a~regular square of float height samples stored completely independently from the~other nodes. It must be stated that our method should not interfere in any way with how this engine traverses this hierarchy in order to render a~scene. The~mip-maps which the~decompression should be able to provide are in fact a~form of level of detail technique, but it must be made clear that the~ability to provide simplified multiresolution representations of every square of the~LOD hierarchy is just a~tiny part of the~multiresolution rendering pipeline, a~LODing terrain engine can certainly not be build solely on this ability. The~application using the~desired method should be able to traverse its multiresolution hierarchy of square nodes on itself in order to render a~scene. After selecting which squares should be displayed (the~lower the~distance, the~more detailed the~displayed square), the~application then should decide for each of the~squares which mip-map of it will be displayed. Thus, the~mip-maps present a~less significant LOD concept inside the~greater LOD concept - the~multiresolution squares hierarchy. The~mip-map selection can be based on the~screen-space area of the~square in order to reduce the~terrain aliasing. For example, when looking at a~certain terrain square from a~side, a~coarser mip-map of it should be chosen than in case we look at it from the~top.

As we already stated, we did not find any paper which solves just the~task of terrain data compression without solving its rendering. Many methods are able to compress multiresolution hierarchies prepared to be used in rendering which introduces unnecessary overhead for us. Thus, to find out how the~terrain height data can be compressed while respecting a~maximum-error bound constraint, we had to look for the~suitable compression inside the~methods the~scope of which is broader. We started with a~survey paper summarizing the~best known multiresolution terrain rendering methods~\cite{survey}. All these methods also handle the~rendering supported by their own LODing hierarchies. However, some of them contain data compression as a sub-task. Some of them are designed to render just a~flat area, others are able to render the~whole planet. For our purpose, the~methods rendering a~flat portion of terrain seemed sufficient to get to know, the~scope of both groups of methods is larger than required anyway, but we dug through all of them with the~aim to find the~most efficient compression inside them. We did not limit our search only to the~methods referenced by this survey paper, we also searched recursively by references from the~already discovered papers and, of course, on the~internet. In the~rest of this section, we will briefly describe the~methods which contain terrain data compression

The~first methods we came accross are C-BDAM\footnote{Compressed Batched Dynamic Adaptive Meshes}~\cite{cbdam} and P-BDAM\footnote{Planet Sized Batched Dynamic Adaptive Meshes}~\cite{pbdam}. Both these methods handle the~LOD rendering too and perform the~data compression in the~refinement of a~node of their~LOD hierarchy. Once the~values of a~certain node are known, they are used to predict the~values of its children as accurately as possible. After that, the~differences between these~predictions and the~real values are computed. These are called residuals. With the~help of them, the~real values can be restored with absolute accuracy. However, the~residuals are then quantized to achieve better compression ratio which means that the~compression is lossy. Then, they are losslessly compressed by an~entropy codec. Both these methods are able to compute the~residuals in the~way which ensures that the~error of the~reconstructed data is kept within a~maximum error bound adjustable by the~user in every node of their LOD hierarchy. This can be achieved by a~slight modification of the~second-generation wavelet lifting scheme~\cite{two-stage}. C-BDAM is designed to render just a~flat portion of terrain, whereas P-BDAM is just C-BDAM modified to be able to render a~whole planet. These modifications do not include any improvements to the~efficiency of the~compression, so, from our point of view, it is suffiecient to know just C-BDAM from these two methods. What makes C-BDAM the~most interesting are two aspects: the~outstanding compression ratio achieved and the~ability to respect a~certain user-set maximum per-sample error bound (the~ratio of 64:1 on the~whole planet with 16m maximum deviation).

Another paper~\cite{jpeg2000terrain} describes a~method for rendering a~flat portion of terrain. This method contains data compression based on the~same principle - the~residuals needed to reconstruct the~children of a~square node of the~terrain LOD hierarchy are compressed. The~computation of residuals is based on the~wavelet-based JPEG2000 standard. This method is not able to reconstruct the~data within a~certain maximum-error bound which makes it less interesting to us. Besides, the~visual artifacts between adjacent nodes of different LODs are not handled by its rendering pipeline, but it needs not bother us anyway.

After summarizing the~available literature, we decided get insipred by the~compression inside C-BDAM and tailor it for our needs to create out own method. Instead of LOD node in C-BDAM, we put a~mip-map in our method. The~compression in our method takes place in the~transition from a~coarser mip-map to the~finer one, analogically to the~transition from a~coarser LOD node to the~finer one in C-BDAM. Note the~crucial difference that We significantly simplified the~compression equations performed in C-BDAM in order to increase the~efficiency and speed of this method, while still being able to satisfy the~required maximum absolute error bound constraint.

In Chapter~\ref{chap:wavelets_comp}, we briefly describe the~basic theory of wavelets and link C-BDAM and our method to it, in Chapter~\ref{chap:outline}, we briefly describe the~basic outline of the~method. In Chapter~\ref{chap:details}, we describe the~details of the~method. In Chapter~\ref{chap:cbdam_comp}, we compare the~core algorithm of this method to the~algorithm of C-BDAM. We present the~results in Section~\ref{sec:results} and then discuss them in Section~\ref{sec:conclusion}.
